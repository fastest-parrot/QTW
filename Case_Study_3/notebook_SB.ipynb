{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 7333 - Quantifying the World\n",
    "## Case Study #3\n",
    "\n",
    "Sterling Beason, Sean Kennedy, Emil Ramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import SVG\n",
    "\n",
    "# IMPORTANT: install rpy2 v3.3.x\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Recommended Installation: 'conda install python-graphviz' (should add 'graphviz' to PATH)\n",
    "from graphviz import Source\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import R Data and Convert to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isSpam</th>\n",
       "      <th>isRe</th>\n",
       "      <th>underscore</th>\n",
       "      <th>priority</th>\n",
       "      <th>isInReplyTo</th>\n",
       "      <th>sortedRec</th>\n",
       "      <th>subPunc</th>\n",
       "      <th>multipartText</th>\n",
       "      <th>hasImages</th>\n",
       "      <th>isPGPsigned</th>\n",
       "      <th>...</th>\n",
       "      <th>subQuesCt</th>\n",
       "      <th>numAtt</th>\n",
       "      <th>numRec</th>\n",
       "      <th>perCaps</th>\n",
       "      <th>hour</th>\n",
       "      <th>perHTML</th>\n",
       "      <th>subBlanks</th>\n",
       "      <th>forwards</th>\n",
       "      <th>avgWordLen</th>\n",
       "      <th>numDlr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.451039</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.376623</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.491289</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.436096</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.817164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.918919</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.116643</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.217391</td>\n",
       "      <td>6.451613</td>\n",
       "      <td>4.234940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9343</th>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.572552</td>\n",
       "      <td>21.0</td>\n",
       "      <td>79.657111</td>\n",
       "      <td>13.793103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.700555</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9344</th>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.436009</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.904255</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9345</th>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.418448</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.703704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.795400</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.252690</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.783951</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.823821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9348 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     isSpam isRe underscore priority isInReplyTo sortedRec subPunc  \\\n",
       "0         F    T          F        F           T         T       F   \n",
       "1         F    F          F        F           F         T       F   \n",
       "2         F    F          F        F           F         T       F   \n",
       "3         F    F          F        F           F         T       F   \n",
       "4         F    T          F        F           F         T       F   \n",
       "...     ...  ...        ...      ...         ...       ...     ...   \n",
       "9343      T    F          F        F           F         T       F   \n",
       "9344      T    F          F        F           F         T       F   \n",
       "9345      T    F          F        F           F         F       F   \n",
       "9346      T    F          F        F           F         T       F   \n",
       "9347      T    F          F        F           F         T       F   \n",
       "\n",
       "     multipartText hasImages isPGPsigned  ... subQuesCt numAtt numRec  \\\n",
       "0                F         F           F  ...         0    0.0      2   \n",
       "1                F         F           F  ...         0    0.0      1   \n",
       "2                F         F           F  ...         0    0.0      1   \n",
       "3                F         F           F  ...         0    0.0      0   \n",
       "4                F         F           F  ...         0    0.0      1   \n",
       "...            ...       ...         ...  ...       ...    ...    ...   \n",
       "9343             F         F           F  ...         1    0.0      1   \n",
       "9344             T         F           F  ...         0    1.0      1   \n",
       "9345             F         F           F  ...         0    0.0      1   \n",
       "9346             F         F           F  ...         0    0.0      1   \n",
       "9347             F         F           F  ...         0    0.0      1   \n",
       "\n",
       "       perCaps  hour    perHTML  subBlanks  forwards  avgWordLen  numDlr  \n",
       "0     4.451039  11.0   0.000000  12.500000  0.000000    4.376623       3  \n",
       "1     7.491289  11.0   0.000000   8.000000  0.000000    4.555556       0  \n",
       "2     7.436096  12.0   0.000000   8.000000  0.000000    4.817164       0  \n",
       "3     5.090909  13.0   0.000000  18.918919  3.125000    4.714286       0  \n",
       "4     6.116643  13.0   0.000000  15.217391  6.451613    4.234940       0  \n",
       "...        ...   ...        ...        ...       ...         ...     ...  \n",
       "9343  8.572552  21.0  79.657111  13.793103  0.000000    4.700555       2  \n",
       "9344  9.436009  23.0   0.000000  10.526316  0.000000    4.904255       4  \n",
       "9345  2.418448   8.0   0.000000  20.000000  0.000000    4.703704       0  \n",
       "9346  7.795400  23.0   0.000000   5.263158  0.000000    5.252690      80  \n",
       "9347  4.783951   6.0   0.000000  14.285714  0.000000    4.823821       1  \n",
       "\n",
       "[9348 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = importr('base')\n",
    "base.load(\"./Data/data.Rda\")\n",
    "rdf_List = base.mget(base.ls())\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    df = ro.conversion.rpy2py(rdf_List[0]) # convert 'emailDFrp' dataset\n",
    "    \n",
    "df = df.reset_index()\n",
    "df = df.drop('index', 1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9348 entries, 0 to 9347\n",
      "Data columns (total 30 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   isSpam         9348 non-null   category\n",
      " 1   isRe           9348 non-null   category\n",
      " 2   underscore     9348 non-null   category\n",
      " 3   priority       9348 non-null   category\n",
      " 4   isInReplyTo    9348 non-null   category\n",
      " 5   sortedRec      9348 non-null   category\n",
      " 6   subPunc        9348 non-null   category\n",
      " 7   multipartText  9348 non-null   category\n",
      " 8   hasImages      9348 non-null   category\n",
      " 9   isPGPsigned    9348 non-null   category\n",
      " 10  subSpamWords   9341 non-null   category\n",
      " 11  noHost         9347 non-null   category\n",
      " 12  numEnd         9348 non-null   category\n",
      " 13  isYelling      9341 non-null   category\n",
      " 14  isOrigMsg      9348 non-null   category\n",
      " 15  isDear         9348 non-null   category\n",
      " 16  isWrote        9348 non-null   category\n",
      " 17  numLines       9348 non-null   int32   \n",
      " 18  bodyCharCt     9348 non-null   int32   \n",
      " 19  subExcCt       9348 non-null   int32   \n",
      " 20  subQuesCt      9348 non-null   int32   \n",
      " 21  numAtt         9348 non-null   float64 \n",
      " 22  numRec         9348 non-null   int32   \n",
      " 23  perCaps        9348 non-null   float64 \n",
      " 24  hour           9348 non-null   float64 \n",
      " 25  perHTML        9348 non-null   float64 \n",
      " 26  subBlanks      9328 non-null   float64 \n",
      " 27  forwards       9348 non-null   float64 \n",
      " 28  avgWordLen     9348 non-null   float64 \n",
      " 29  numDlr         9348 non-null   int32   \n",
      "dtypes: category(17), float64(7), int32(6)\n",
      "memory usage: 887.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isSpam           False\n",
      "isRe             False\n",
      "underscore       False\n",
      "priority         False\n",
      "isInReplyTo      False\n",
      "sortedRec        False\n",
      "subPunc          False\n",
      "multipartText    False\n",
      "hasImages        False\n",
      "isPGPsigned      False\n",
      "subSpamWords      True\n",
      "noHost            True\n",
      "numEnd           False\n",
      "isYelling         True\n",
      "isOrigMsg        False\n",
      "isDear           False\n",
      "isWrote          False\n",
      "numLines         False\n",
      "bodyCharCt       False\n",
      "subExcCt         False\n",
      "subQuesCt        False\n",
      "numAtt           False\n",
      "numRec           False\n",
      "perCaps          False\n",
      "hour             False\n",
      "perHTML          False\n",
      "subBlanks         True\n",
      "forwards         False\n",
      "avgWordLen       False\n",
      "numDlr           False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 columns with NAs \n",
    "\n",
    "- subSpamWords (category)\n",
    "\n",
    "- noHost (category)\n",
    "\n",
    "- isYelling (category)\n",
    "\n",
    "- subBlanks (float)\n",
    "\n",
    "Let's analyze the categorical variables first:\n",
    "\n",
    "***subSpamWords***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[F, T, NaN]\n",
       "Categories (2, object): [F, T]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subSpamWords.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '0'),\n",
       " Text(0, 0, '1,000'),\n",
       " Text(0, 0, '2,000'),\n",
       " Text(0, 0, '3,000'),\n",
       " Text(0, 0, '4,000'),\n",
       " Text(0, 0, '5,000'),\n",
       " Text(0, 0, '6,000'),\n",
       " Text(0, 0, '7,000'),\n",
       " Text(0, 0, '8,000')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spam_na = df[df.subSpamWords.isna()]\n",
    "group_by_spam = df.groupby(['subSpamWords', 'isSpam']).count().reset_index()\n",
    "p1 = sns.barplot(data = group_by_spam, x='subSpamWords', y='isRe', hue='isSpam')\n",
    "p1.set_title('Sub Spam Words vs Is Spam')\n",
    "y_ticklabels = [f'{y:,.0f}' for y in p1.get_yticks()]\n",
    "p1.set_yticklabels(y_ticklabels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Partioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() # TODO: Impute NAs, don't drop them\n",
    "\n",
    "features = df[df.columns.difference(['isSpam'])]\n",
    "\n",
    "\n",
    "X = pd.get_dummies(features, drop_first=True)\n",
    "y = df['isSpam'].astype('object').apply(lambda x: 1 if x == 'T' else 0)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=7333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9302325581395349"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=7333)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "precision_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'splitter': 'best',\n",
       " 'max_depth': None,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'max_features': None,\n",
       " 'random_state': 7333,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'class_weight': None,\n",
       " 'presort': 'deprecated',\n",
       " 'ccp_alpha': 0.0,\n",
       " 'n_features_': 29,\n",
       " 'n_outputs_': 1,\n",
       " 'classes_': array([0, 1]),\n",
       " 'n_classes_': 2,\n",
       " 'max_features_': 29,\n",
       " 'tree_': <sklearn.tree._tree.Tree at 0x7fda7fab7308>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "cv = StratifiedShuffleSplit(n_splits,test_size=.2, train_size=.8, random_state=7333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = ['gini', 'entropy'] # define possible splitting criteria\n",
    "splitters = ['best', 'random'] \n",
    "max_depth = list(range(20, 100, 5))\n",
    "min_samples_split = list(range(1,5, 1))\n",
    "min_samples_leaf = list(range(5, 50, 3))\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "random_state = 7333\n",
    "min_fraction = None\n",
    "max_leaf_nodes = [range(5, 20, 3)]\n",
    "scoring = {\n",
    "            'Accuracy':'accuracy'\n",
    "            , 'F-1 Score':'f1'\n",
    "            , 'AUC':'roc_auc'\n",
    "            , 'Precision':'precision'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning:\n",
    "\n",
    "General grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of best estimator: 0.9158110882956879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    1.3s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('decision_tree', clf)])\n",
    "clf_pipe = GridSearchCV(pipe\n",
    "                   , cv=cv\n",
    "                   ,param_grid = {\n",
    "                                 'decision_tree__criterion':criteria,\n",
    "                                 #'decision_tree__criterion':criteria,\n",
    "                                 }\n",
    "                   , verbose=True\n",
    "                   , n_jobs=-1\n",
    "                   , scoring=scoring\n",
    "                   , refit='Precision'\n",
    "                   , error_score=0.0)\n",
    "clf_fit = clf_pipe.fit(X_train, y_train.values.ravel())\n",
    "clf_predict = clf_fit.best_estimator_.predict(X_test)\n",
    "print(f'Precision score of best estimator: {precision_score(y_test, clf_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('decision_tree',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='entropy', max_depth=None,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=7333,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split0_test_Precision</th>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.91601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_Precision</th>\n",
       "      <td>0.929155</td>\n",
       "      <td>0.915567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_Precision</th>\n",
       "      <td>0.916883</td>\n",
       "      <td>0.941645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_Precision</th>\n",
       "      <td>0.934605</td>\n",
       "      <td>0.937158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_Precision</th>\n",
       "      <td>0.927419</td>\n",
       "      <td>0.910026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_Precision</th>\n",
       "      <td>0.925484</td>\n",
       "      <td>0.924081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_Precision</th>\n",
       "      <td>0.00651087</td>\n",
       "      <td>0.0127645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_Precision</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'decision_tree__criterion': 'entropy'}</td>\n",
       "      <td>{'decision_tree__criterion': 'gini'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             1  \\\n",
       "split0_test_Precision                                 0.919355   \n",
       "split1_test_Precision                                 0.929155   \n",
       "split2_test_Precision                                 0.916883   \n",
       "split3_test_Precision                                 0.934605   \n",
       "split4_test_Precision                                 0.927419   \n",
       "mean_test_Precision                                   0.925484   \n",
       "std_test_Precision                                  0.00651087   \n",
       "rank_test_Precision                                          1   \n",
       "params                 {'decision_tree__criterion': 'entropy'}   \n",
       "\n",
       "                                                          0  \n",
       "split0_test_Precision                               0.91601  \n",
       "split1_test_Precision                              0.915567  \n",
       "split2_test_Precision                              0.941645  \n",
       "split3_test_Precision                              0.937158  \n",
       "split4_test_Precision                              0.910026  \n",
       "mean_test_Precision                                0.924081  \n",
       "std_test_Precision                                0.0127645  \n",
       "rank_test_Precision                                       2  \n",
       "params                 {'decision_tree__criterion': 'gini'}  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(clf_fit.cv_results_)\n",
    "scores = [col for col in results.columns if 'test_Precision' in col]\n",
    "scores.append('params')\n",
    "results[scores].sort_values(['rank_test_Precision']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entropy** appears slightly better.... given that this precision is worse than baseline, we should continue our search and consider sticking with **gini**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Precision score of best estimator: 0.9564270152505446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "clf_pipe = GridSearchCV(pipe\n",
    "                   , cv=cv\n",
    "                   ,param_grid = {\n",
    "                                 'decision_tree__criterion':criteria,\n",
    "                                 'decision_tree__splitter':splitters,\n",
    "                                 }\n",
    "                   , verbose=True\n",
    "                   , n_jobs=-1\n",
    "                   , scoring=scoring\n",
    "                   , refit='Precision'\n",
    "                   , error_score=0.0)\n",
    "clf_fit = clf_pipe.fit(X_train, y_train.values.ravel())\n",
    "clf_predict = clf_fit.best_estimator_.predict(X_test)\n",
    "print(f'Precision score of best estimator: {precision_score(y_test, clf_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('decision_tree',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=7333,\n",
       "                                        splitter='random'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decision_tree__criterion': 'gini', 'decision_tree__splitter': 'random'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(clf_fit.cv_results_)\n",
    "scores = [col for col in results.columns if 'test_Precision' in col]\n",
    "scores.append('params')\n",
    "sorted_results = results[scores].sort_values(['rank_test_Precision']).T\n",
    "sorted_results[1].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of best estimator: 0.9653579676674365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "clf_pipe = GridSearchCV(pipe\n",
    "                   , cv=cv\n",
    "                   ,param_grid = {\n",
    "                                 'decision_tree__criterion':criteria,\n",
    "                                 'decision_tree__splitter':splitters,\n",
    "                                 'decision_tree__max_depth':max_depth,\n",
    "                                 }\n",
    "                   , verbose=True\n",
    "                   , n_jobs=-1\n",
    "                   , scoring=scoring\n",
    "                   , refit='Precision'\n",
    "                   , error_score=0.0)\n",
    "clf_fit = clf_pipe.fit(X_train, y_train.values.ravel())\n",
    "clf_predict = clf_fit.best_estimator_.predict(X_test)\n",
    "print(f'Precision score of best estimator: {precision_score(y_test, clf_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('decision_tree',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=20,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=7333,\n",
       "                                        splitter='random'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decision_tree__criterion': 'gini',\n",
       " 'decision_tree__max_depth': 20,\n",
       " 'decision_tree__splitter': 'random'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(clf_fit.cv_results_)\n",
    "scores = [col for col in results.columns if 'test_Precision' in col]\n",
    "scores.append('params')\n",
    "sorted_results = results[scores].sort_values(['rank_test_Precision']).T\n",
    "sorted_results[1].params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting max_depth = 20 seems to have a sizeable improvement on Precision, let's keep that in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1168 tasks      | elapsed:    6.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of best estimator: 0.9653579676674365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1280 out of 1280 | elapsed:    6.9s finished\n"
     ]
    }
   ],
   "source": [
    "clf_pipe = GridSearchCV(pipe\n",
    "                   , cv=cv\n",
    "                   ,param_grid = {\n",
    "                                 'decision_tree__criterion':criteria,\n",
    "                                 'decision_tree__splitter':splitters,\n",
    "                                 'decision_tree__max_depth':max_depth,\n",
    "                                 'decision_tree__min_samples_split': min_samples_split\n",
    "                                 }\n",
    "                   , verbose=True\n",
    "                   , n_jobs=-1\n",
    "                   , scoring=scoring\n",
    "                   , refit='Precision'\n",
    "                   , error_score=0.0)\n",
    "clf_fit = clf_pipe.fit(X_train, y_train.values.ravel())\n",
    "clf_predict = clf_fit.best_estimator_.predict(X_test)\n",
    "print(f'Precision score of best estimator: {precision_score(y_test, clf_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('decision_tree',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=20,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=7333,\n",
       "                                        splitter='random'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decision_tree__criterion': 'gini',\n",
       " 'decision_tree__max_depth': 20,\n",
       " 'decision_tree__min_samples_split': 1,\n",
       " 'decision_tree__splitter': 'random'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(clf_fit.cv_results_)\n",
    "scores = [col for col in results.columns if 'test_Precision' in col]\n",
    "scores.append('params')\n",
    "sorted_results = results[scores].sort_values(['rank_test_Precision']).T\n",
    "sorted_results[1].params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**min_samples_split** seems to best at the lowest possible value: explanantion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3840 candidates, totalling 19200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1656 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3056 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4856 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 7056 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 9656 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 12656 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 16056 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of best estimator: 0.9108695652173913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 19200 out of 19200 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "clf_pipe = GridSearchCV(pipe\n",
    "                   , cv=cv\n",
    "                   ,param_grid = {\n",
    "                                 'decision_tree__criterion':criteria,\n",
    "                                 'decision_tree__splitter':splitters,\n",
    "                                 'decision_tree__max_depth':max_depth,\n",
    "                                 'decision_tree__min_samples_split': min_samples_split,\n",
    "                                 'decision_tree__min_samples_leaf': min_samples_leaf,\n",
    "                                 }\n",
    "                   , verbose=True\n",
    "                   , n_jobs=-1\n",
    "                   , scoring=scoring\n",
    "                   , refit='Precision'\n",
    "                   , error_score=0.0)\n",
    "clf_fit = clf_pipe.fit(X_train, y_train.values.ravel())\n",
    "clf_predict = clf_fit.best_estimator_.predict(X_test)\n",
    "print(f'Precision score of best estimator: {precision_score(y_test, clf_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('decision_tree',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=20,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=5, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=7333,\n",
       "                                        splitter='random'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decision_tree__criterion': 'gini',\n",
       " 'decision_tree__max_depth': 20,\n",
       " 'decision_tree__min_samples_leaf': 5,\n",
       " 'decision_tree__min_samples_split': 1,\n",
       " 'decision_tree__splitter': 'random'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(clf_fit.cv_results_)\n",
    "scores = [col for col in results.columns if 'test_Precision' in col]\n",
    "scores.append('params')\n",
    "sorted_results = results[scores].sort_values(['rank_test_Precision']).T\n",
    "sorted_results[1].params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Decision Tree\n",
    "\n",
    "**Note:** You may have to scroll to view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_startupinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    768\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1515\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-412a7262fb29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ham'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format, renderer, formatter, quiet)\u001b[0m\n\u001b[1;32m    136\u001b[0m         out = backend.pipe(self._engine, format, data,\n\u001b[1;32m    137\u001b[0m                            \u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                            quiet=quiet)\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(engine, format, data, renderer, formatter, quiet)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \"\"\"\n\u001b[1;32m    243\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "graph = Source(tree.export_graphviz(clf, out_file=None, feature_names=X.columns, class_names=['spam', 'ham'], filled = True))\n",
    "\n",
    "display(SVG(graph.pipe(format='svg')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
